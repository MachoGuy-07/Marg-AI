{"ast":null,"code":"var _s = $RefreshSig$();\n// client/src/components/PostureAnalyzer.jsx\n\nimport { useEffect, useRef } from \"react\";\nimport { FaceMesh } from \"@mediapipe/face_mesh\";\nexport default function PostureAnalyzer({\n  videoRef,\n  onScoreUpdate\n}) {\n  _s();\n  const faceMeshRef = useRef(null);\n  const intervalRef = useRef(null);\n  const faceFrames = useRef(0);\n  const totalFrames = useRef(0);\n  const headMovement = useRef(0);\n  const lastNose = useRef(null);\n  useEffect(() => {\n    if (!(videoRef !== null && videoRef !== void 0 && videoRef.current)) return;\n    const faceMesh = new FaceMesh({\n      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`\n    });\n    faceMesh.setOptions({\n      maxNumFaces: 1,\n      refineLandmarks: true,\n      minDetectionConfidence: 0.5,\n      minTrackingConfidence: 0.5\n    });\n    faceMesh.onResults(results => {\n      totalFrames.current++;\n      if (results.multiFaceLandmarks) {\n        faceFrames.current++;\n        const landmarks = results.multiFaceLandmarks[0];\n\n        // ⭐ BASIC LANDMARKS\n        const leftEye = landmarks[33];\n        const rightEye = landmarks[263];\n        const nose = landmarks[1];\n\n        // ⭐ CHEEK RISE SMILE DETECTION (eye squint)\n        const faceWidth = Math.abs(landmarks[234].x - landmarks[454].x);\n        const eyeSquintLeft = Math.abs(landmarks[159].y - landmarks[145].y) / faceWidth;\n        const eyeSquintRight = Math.abs(landmarks[386].y - landmarks[374].y) / faceWidth;\n        const avgSquint = (eyeSquintLeft + eyeSquintRight) / 2;\n        let emotion = \"Neutral\";\n\n        // Smile only when cheeks rise\n        if (avgSquint < 0.03) emotion = \"Smile\";\n\n        // ⭐ EYE CONTACT\n        const eyeCenterX = (leftEye.x + rightEye.x) / 2;\n        const gazeOffset = Math.abs(nose.x - eyeCenterX);\n        const eyeScore = 1 - Math.min(gazeOffset * 3, 1);\n\n        // ⭐ HEAD MOVEMENT\n        if (lastNose.current) {\n          const dx = nose.x - lastNose.current.x;\n          const dy = nose.y - lastNose.current.y;\n          headMovement.current += Math.sqrt(dx * dx + dy * dy);\n        }\n        lastNose.current = nose;\n        const engagement = faceFrames.current / totalFrames.current;\n        const stability = Math.max(0, 1 - headMovement.current * 5);\n        const postureScore = eyeScore * 0.4 + engagement * 0.3 + stability * 0.3;\n\n        // ⭐ SEND SCORE + EMOTION\n        onScoreUpdate === null || onScoreUpdate === void 0 ? void 0 : onScoreUpdate(postureScore, emotion);\n      }\n    });\n    faceMeshRef.current = faceMesh;\n    intervalRef.current = setInterval(async () => {\n      if (videoRef.current.readyState >= 2) {\n        await faceMesh.send({\n          image: videoRef.current\n        });\n      }\n    }, 100);\n    return () => clearInterval(intervalRef.current);\n  }, [videoRef, onScoreUpdate]);\n  return null;\n}\n_s(PostureAnalyzer, \"4S5Jic0uTz9cHVcjaryMclaSu9c=\");\n_c = PostureAnalyzer;\nvar _c;\n$RefreshReg$(_c, \"PostureAnalyzer\");","map":{"version":3,"names":["useEffect","useRef","FaceMesh","PostureAnalyzer","videoRef","onScoreUpdate","_s","faceMeshRef","intervalRef","faceFrames","totalFrames","headMovement","lastNose","current","faceMesh","locateFile","file","setOptions","maxNumFaces","refineLandmarks","minDetectionConfidence","minTrackingConfidence","onResults","results","multiFaceLandmarks","landmarks","leftEye","rightEye","nose","faceWidth","Math","abs","x","eyeSquintLeft","y","eyeSquintRight","avgSquint","emotion","eyeCenterX","gazeOffset","eyeScore","min","dx","dy","sqrt","engagement","stability","max","postureScore","setInterval","readyState","send","image","clearInterval","_c","$RefreshReg$"],"sources":["/Users/siva/Desktop/AI-INTERVIEW/client/src/components/PostureAnalyzer.jsx"],"sourcesContent":["// client/src/components/PostureAnalyzer.jsx\n\nimport { useEffect, useRef } from \"react\";\nimport { FaceMesh } from \"@mediapipe/face_mesh\";\n\nexport default function PostureAnalyzer({ videoRef, onScoreUpdate }) {\n  const faceMeshRef = useRef(null);\n  const intervalRef = useRef(null);\n\n  const faceFrames = useRef(0);\n  const totalFrames = useRef(0);\n  const headMovement = useRef(0);\n  const lastNose = useRef(null);\n\n  useEffect(() => {\n    if (!videoRef?.current) return;\n\n    const faceMesh = new FaceMesh({\n      locateFile: (file) =>\n        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,\n    });\n\n    faceMesh.setOptions({\n      maxNumFaces: 1,\n      refineLandmarks: true,\n      minDetectionConfidence: 0.5,\n      minTrackingConfidence: 0.5,\n    });\n\n    faceMesh.onResults((results) => {\n      totalFrames.current++;\n\n      if (results.multiFaceLandmarks) {\n        faceFrames.current++;\n\n        const landmarks = results.multiFaceLandmarks[0];\n\n        // ⭐ BASIC LANDMARKS\n        const leftEye = landmarks[33];\n        const rightEye = landmarks[263];\n        const nose = landmarks[1];\n\n        // ⭐ CHEEK RISE SMILE DETECTION (eye squint)\n        const faceWidth = Math.abs(landmarks[234].x - landmarks[454].x);\n\n        const eyeSquintLeft =\n          Math.abs(landmarks[159].y - landmarks[145].y) / faceWidth;\n\n        const eyeSquintRight =\n          Math.abs(landmarks[386].y - landmarks[374].y) / faceWidth;\n\n        const avgSquint = (eyeSquintLeft + eyeSquintRight) / 2;\n\n        let emotion = \"Neutral\";\n\n        // Smile only when cheeks rise\n        if (avgSquint < 0.03) emotion = \"Smile\";\n\n        // ⭐ EYE CONTACT\n        const eyeCenterX = (leftEye.x + rightEye.x) / 2;\n        const gazeOffset = Math.abs(nose.x - eyeCenterX);\n        const eyeScore = 1 - Math.min(gazeOffset * 3, 1);\n\n        // ⭐ HEAD MOVEMENT\n        if (lastNose.current) {\n          const dx = nose.x - lastNose.current.x;\n          const dy = nose.y - lastNose.current.y;\n          headMovement.current += Math.sqrt(dx * dx + dy * dy);\n        }\n        lastNose.current = nose;\n\n        const engagement = faceFrames.current / totalFrames.current;\n        const stability = Math.max(0, 1 - headMovement.current * 5);\n\n        const postureScore =\n          eyeScore * 0.4 +\n          engagement * 0.3 +\n          stability * 0.3;\n\n        // ⭐ SEND SCORE + EMOTION\n        onScoreUpdate?.(postureScore, emotion);\n      }\n    });\n\n    faceMeshRef.current = faceMesh;\n\n    intervalRef.current = setInterval(async () => {\n      if (videoRef.current.readyState >= 2) {\n        await faceMesh.send({ image: videoRef.current });\n      }\n    }, 100);\n\n    return () => clearInterval(intervalRef.current);\n  }, [videoRef, onScoreUpdate]);\n\n  return null;\n}"],"mappings":";AAAA;;AAEA,SAASA,SAAS,EAAEC,MAAM,QAAQ,OAAO;AACzC,SAASC,QAAQ,QAAQ,sBAAsB;AAE/C,eAAe,SAASC,eAAeA,CAAC;EAAEC,QAAQ;EAAEC;AAAc,CAAC,EAAE;EAAAC,EAAA;EACnE,MAAMC,WAAW,GAAGN,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMO,WAAW,GAAGP,MAAM,CAAC,IAAI,CAAC;EAEhC,MAAMQ,UAAU,GAAGR,MAAM,CAAC,CAAC,CAAC;EAC5B,MAAMS,WAAW,GAAGT,MAAM,CAAC,CAAC,CAAC;EAC7B,MAAMU,YAAY,GAAGV,MAAM,CAAC,CAAC,CAAC;EAC9B,MAAMW,QAAQ,GAAGX,MAAM,CAAC,IAAI,CAAC;EAE7BD,SAAS,CAAC,MAAM;IACd,IAAI,EAACI,QAAQ,aAARA,QAAQ,eAARA,QAAQ,CAAES,OAAO,GAAE;IAExB,MAAMC,QAAQ,GAAG,IAAIZ,QAAQ,CAAC;MAC5Ba,UAAU,EAAGC,IAAI,IACf,qDAAqDA,IAAI;IAC7D,CAAC,CAAC;IAEFF,QAAQ,CAACG,UAAU,CAAC;MAClBC,WAAW,EAAE,CAAC;MACdC,eAAe,EAAE,IAAI;MACrBC,sBAAsB,EAAE,GAAG;MAC3BC,qBAAqB,EAAE;IACzB,CAAC,CAAC;IAEFP,QAAQ,CAACQ,SAAS,CAAEC,OAAO,IAAK;MAC9Bb,WAAW,CAACG,OAAO,EAAE;MAErB,IAAIU,OAAO,CAACC,kBAAkB,EAAE;QAC9Bf,UAAU,CAACI,OAAO,EAAE;QAEpB,MAAMY,SAAS,GAAGF,OAAO,CAACC,kBAAkB,CAAC,CAAC,CAAC;;QAE/C;QACA,MAAME,OAAO,GAAGD,SAAS,CAAC,EAAE,CAAC;QAC7B,MAAME,QAAQ,GAAGF,SAAS,CAAC,GAAG,CAAC;QAC/B,MAAMG,IAAI,GAAGH,SAAS,CAAC,CAAC,CAAC;;QAEzB;QACA,MAAMI,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACN,SAAS,CAAC,GAAG,CAAC,CAACO,CAAC,GAAGP,SAAS,CAAC,GAAG,CAAC,CAACO,CAAC,CAAC;QAE/D,MAAMC,aAAa,GACjBH,IAAI,CAACC,GAAG,CAACN,SAAS,CAAC,GAAG,CAAC,CAACS,CAAC,GAAGT,SAAS,CAAC,GAAG,CAAC,CAACS,CAAC,CAAC,GAAGL,SAAS;QAE3D,MAAMM,cAAc,GAClBL,IAAI,CAACC,GAAG,CAACN,SAAS,CAAC,GAAG,CAAC,CAACS,CAAC,GAAGT,SAAS,CAAC,GAAG,CAAC,CAACS,CAAC,CAAC,GAAGL,SAAS;QAE3D,MAAMO,SAAS,GAAG,CAACH,aAAa,GAAGE,cAAc,IAAI,CAAC;QAEtD,IAAIE,OAAO,GAAG,SAAS;;QAEvB;QACA,IAAID,SAAS,GAAG,IAAI,EAAEC,OAAO,GAAG,OAAO;;QAEvC;QACA,MAAMC,UAAU,GAAG,CAACZ,OAAO,CAACM,CAAC,GAAGL,QAAQ,CAACK,CAAC,IAAI,CAAC;QAC/C,MAAMO,UAAU,GAAGT,IAAI,CAACC,GAAG,CAACH,IAAI,CAACI,CAAC,GAAGM,UAAU,CAAC;QAChD,MAAME,QAAQ,GAAG,CAAC,GAAGV,IAAI,CAACW,GAAG,CAACF,UAAU,GAAG,CAAC,EAAE,CAAC,CAAC;;QAEhD;QACA,IAAI3B,QAAQ,CAACC,OAAO,EAAE;UACpB,MAAM6B,EAAE,GAAGd,IAAI,CAACI,CAAC,GAAGpB,QAAQ,CAACC,OAAO,CAACmB,CAAC;UACtC,MAAMW,EAAE,GAAGf,IAAI,CAACM,CAAC,GAAGtB,QAAQ,CAACC,OAAO,CAACqB,CAAC;UACtCvB,YAAY,CAACE,OAAO,IAAIiB,IAAI,CAACc,IAAI,CAACF,EAAE,GAAGA,EAAE,GAAGC,EAAE,GAAGA,EAAE,CAAC;QACtD;QACA/B,QAAQ,CAACC,OAAO,GAAGe,IAAI;QAEvB,MAAMiB,UAAU,GAAGpC,UAAU,CAACI,OAAO,GAAGH,WAAW,CAACG,OAAO;QAC3D,MAAMiC,SAAS,GAAGhB,IAAI,CAACiB,GAAG,CAAC,CAAC,EAAE,CAAC,GAAGpC,YAAY,CAACE,OAAO,GAAG,CAAC,CAAC;QAE3D,MAAMmC,YAAY,GAChBR,QAAQ,GAAG,GAAG,GACdK,UAAU,GAAG,GAAG,GAChBC,SAAS,GAAG,GAAG;;QAEjB;QACAzC,aAAa,aAAbA,aAAa,uBAAbA,aAAa,CAAG2C,YAAY,EAAEX,OAAO,CAAC;MACxC;IACF,CAAC,CAAC;IAEF9B,WAAW,CAACM,OAAO,GAAGC,QAAQ;IAE9BN,WAAW,CAACK,OAAO,GAAGoC,WAAW,CAAC,YAAY;MAC5C,IAAI7C,QAAQ,CAACS,OAAO,CAACqC,UAAU,IAAI,CAAC,EAAE;QACpC,MAAMpC,QAAQ,CAACqC,IAAI,CAAC;UAAEC,KAAK,EAAEhD,QAAQ,CAACS;QAAQ,CAAC,CAAC;MAClD;IACF,CAAC,EAAE,GAAG,CAAC;IAEP,OAAO,MAAMwC,aAAa,CAAC7C,WAAW,CAACK,OAAO,CAAC;EACjD,CAAC,EAAE,CAACT,QAAQ,EAAEC,aAAa,CAAC,CAAC;EAE7B,OAAO,IAAI;AACb;AAACC,EAAA,CA3FuBH,eAAe;AAAAmD,EAAA,GAAfnD,eAAe;AAAA,IAAAmD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}